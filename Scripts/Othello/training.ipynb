{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training d'un agent Othello"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importation des modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Board import Board, Signal\n",
    "from Agent import Memory, Model, encode_action, game_over_from_signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display # to display images\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "## Définition d'un mmodèle de réseau de neurones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # Input (2, 8, 8,)\n",
    "        # Output (65,)\n",
    "        self.input_layer = nn.Linear(128, 128)\n",
    "        self.hidden_layer_1 = nn.Linear(128, 128)\n",
    "        self.hidden_layer_2 = nn.Linear(128, 128)\n",
    "        self.hidden_layer_3 = nn.Linear(128, 128)\n",
    "        self.hidden_layer_4 = nn.Linear(128, 128)\n",
    "        self.hidden_layer_5 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_6 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_7 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_8 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_9 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_10 = nn.Linear(128, 128)\n",
    "        # self.hidden_layer_11 = nn.Linear(128, 128)\n",
    "        # self.input_layer = nn.Conv2d(2, 128, 3, padding=1)\n",
    "        # self.hidden_layer_1 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        # self.hidden_layer_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        # self.hidden_layer_3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        # self.hidden_layer_4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        # self.hidden_layer_5 = nn.Linear(128*8*8, 128*8)\n",
    "        # self.hidden_layer_6 = nn.Linear(128*8, 128)\n",
    "        self.output_layer = nn.Linear(128, 65)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = F.relu(self.hidden_layer_1(x))\n",
    "        x = F.relu(self.hidden_layer_2(x))\n",
    "        x = F.relu(self.hidden_layer_3(x))\n",
    "        x = F.relu(self.hidden_layer_4(x))\n",
    "        x = F.relu(self.hidden_layer_5(x))\n",
    "        # x = F.relu(self.hidden_layer_6(x))\n",
    "        # x = F.relu(self.hidden_layer_7(x))\n",
    "        # x = F.relu(self.hidden_layer_8(x))\n",
    "        # x = F.relu(self.hidden_layer_9(x))\n",
    "        # x = F.relu(self.hidden_layer_10(x))\n",
    "        # x = F.relu(self.hidden_layer_11(x))\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_from_signal(signal: Signal, board: Board):\n",
    "    reward = 0\n",
    "    if signal is Signal.ILLEGAL_MOVE:\n",
    "            reward = -1\n",
    "    elif signal is Signal.VALID_MOVE:\n",
    "        reward = 1\n",
    "    else: # Game over\n",
    "        winner = board.get_winner()\n",
    "        if winner == 1: # White\n",
    "            reward = 100\n",
    "        elif winner == -1: # Black\n",
    "            reward = -100\n",
    "        else: # Draw\n",
    "            reward = -50\n",
    "    return reward\n",
    "\n",
    "def game_over_from_signal(signal: Signal, board: Board):\n",
    "    game_over = signal in [Signal.GAME_OVER, Signal.ILLEGAL_MOVE]\n",
    "    return game_over"
   ]
  },
  {
   "source": [
    "## Méthode de visualisation des q_matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_q(q: list):\n",
    "    dimension = (128, 128)\n",
    "    max_negative = np.min([np.min(q), 0])\n",
    "    max_positive = np.max([np.max(q), 0])\n",
    "    image = Image.new('RGBA', dimension, (255,255,225,255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    y = 0\n",
    "    i = 0\n",
    "    for l in range(8):\n",
    "        x = 0\n",
    "        for c in range(8):\n",
    "            xy = [(x + 1, y + 1), (x + 14, y + 14)]\n",
    "            r = q[i]\n",
    "            if r > 0:\n",
    "                # a = min(255, max(0, int(r * 1 * 255)))\n",
    "                a = int(r / max_positive * 255)\n",
    "                color = (0,0,255,a)\n",
    "                draw.rectangle(xy, fill=color)\n",
    "            elif r < 0:\n",
    "                # a = min(255, max(0, int(-r * 1 * 255)))\n",
    "                a = int(r / max_negative * 255)\n",
    "                color = (255,0,0,a)\n",
    "                draw.rectangle(xy, fill=color)\n",
    "            x += 16\n",
    "            i += 1\n",
    "        y += 16\n",
    "    display(image)"
   ]
  },
  {
   "source": [
    "## Premiere étape : apprentissage d'un seul coup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, before training:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CD235F2760>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADRklEQVR4nO2dT4uNcRiG75+mbMRSFs6rKEosNEmhJKWQj8CCDaVBmrGQhSyY5E9qbFjwEYRS0hRKmixIUZT3tZAl2dh4LDznCzxj5b6u/dW9uebZnN+c0yL6ENgyIUmtjY5W5IjhtiSpdSdL69FfT3+66M9KUmujLSU9hte5/7G4vy73txb3X6V/qeiflSS1blvFV/Qvl5RE+G8gAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMxpfBzsDRfAnPF7gI0VOWJ4l/7hon9XktS6IxVf0d9Jf0XR/57+pqL/VpJaGx0s6THcT39l0f8mSWrdh4qv6NdzAcwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMzhPYA5XABzxu8BnlfkiGFH+jNF/7IkqXXLK76i/5H7m4v7b9J/VPT3pX+66F9N/1DRvydJat1kxVf0C1wAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAc3gPYA4XwJwJSVLrXpTs6Lenf6boX5EW//0Eat1Ucf9G7h8v7s+lf6PoT6Vf+kOMGH6n/6To7+ECmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmMN7AHO4AOaM3wM8KNnRH5Ck1kajkh7DkPulz+MV/Vz6F4r++fTXFP3P6R8r+rekf/J7A6eK/jUugDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDm8BzCHC2DO+PcCvlTkiGG1pEV/Ht/aaGdx/1nuLyvu/8z9mh5/nzOodQvF/cncf1zc35v7T4v7u7kA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5vAewBwugDnj7wdYVbKj/yr9k++731X059OfLvqz6S/2PcKGiq/o36e/tuh/kqTWRrMlPYZpLoA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5vAcwhwtgzvg9QM2OXumX/z89/V1Ff16SWhtdLOkxnMv9/cX9h7k/U9y/nPsnivs3c39pcf8XF8AcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAc3gOY8wd3OAPlhusikwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CCD4689BE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQmAQAwAwVPsw/7LspKzBxFO3Jl/II8ln2xzXnOQta9egLUEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNA3LF6gU/Yzmdz83p3jwVcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI8w0c4xdfvadcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQdwO0DQjCJ5xeEwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CD235F2AC0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADJElEQVR4nO2dQYtOcRSHf38NkygZGRvuVWIhUlaams2wsPQplBRZsLOyYyFKyqewtMBGTVZKZEHKvWxmZKRIw+LYnPcLnKuU3/Psn867eDqbe+59W8QQAlvmJKm1br4iR4ybkqTW7yxNj+F7+nuK/hdJaq07UdJjfJnzdxXnf8v5J4vzX6T/uugfkyS1vlV8xRBbSiL8NxCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5jQeB3vDBjBndg+wtyJHjJ/TXyr6q5Kk1i9UfMWwkf7Wov9bklrrFkt6jOvp3y/6FyRN/v1q/cGi/4ENYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA73AOawAcyZ3QPcqsgR49X0HxT98+kfLvrv0j9U9N+nf6PoX0//StG/nf7lon8n/X1Ff40NYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA73AOawAcyZkyS1vivZMYzpT/3e/5GSHuPbnL+7OP9rzr9YnH8v/cdF/4wkqfXbKr5i+JXza3qMbAB3CMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzuAcwhw1gzuweoPR+uWJYk6Y/T1frdxTn/0h/6vf2p/pTn+cfLekxvkl/ueg/YwOYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYwz2AOWwAc2b/F/CoIkeMZyVNfp7fWne6OP9J+gtFf0OS1PqKLsWg9BeL/roktdatlvQYl3L+geL8j2wAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAc7gHMIcNYM7s+wBT34/fXvR/SlJr3f6SHuOn9B8W/XPpnyr6zyX98+8btNbdLOkxXmMDmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmMM9gDlsAHNm9wC1F+RjGNKf+n788ZIe46v07xb9S5L+xvf+V4rzn+b8+eL8zfRb0Q82gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jzB2gnA+XEGH/hAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# New model\n",
    "board = Board()\n",
    "model = Model()\n",
    "learning_rate = 0.3\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Get initial state from the board\n",
    "initial_s, signal = board.reset()\n",
    "initial_s = torch.tensor(initial_s, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "# Predict an action\n",
    "a_scores = model(initial_s)\n",
    "a = torch.argmax(a_scores).item()\n",
    "encoded_a = encode_action(a)\n",
    "\n",
    "# Perform the action in the game\n",
    "s, signal = board.step(encoded_a)\n",
    "next_s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "# Process the signal\n",
    "r = reward_from_signal(signal, board)\n",
    "done = game_over_from_signal(signal, board)\n",
    "\n",
    "# Q Learning\n",
    "target_q = torch.zeros((65,), dtype=torch.float)\n",
    "\n",
    "# Add the reward and action\n",
    "target_q[a] = r\n",
    "\n",
    "# Render model before the training\n",
    "print(\"Q_matrix of initial state, before training:\")\n",
    "q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "render_q(q_pred.tolist()[0])\n",
    "\n",
    "# Toggle on train mode\n",
    "model.train()\n",
    "\n",
    "for i in range(16):\n",
    "    # Compute loss on the difference between model output and target_q\n",
    "    q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "    loss = criterion(torch.tensor(target_q, dtype=torch.float), q_pred)\n",
    "\n",
    "    # Let the optimizer do the backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Target Q matrix:\")\n",
    "render_q(target_q.tolist())\n",
    "\n",
    "# Render model after the training\n",
    "print(\"Q_matrix of initial state, after training:\")\n",
    "q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "render_q(q_pred.tolist()[0])"
   ]
  },
  {
   "source": [
    "## Deuxième étape : apprentissage du premier état avec historique"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, before training:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CC89361610>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADHklEQVR4nO2d2WpUURBF95GOKDibIA65jfOAov//FYrikETDue1ASJwFxYjlS90fqO4n91rvi0rCol66crpF9BDYMpMktflGyY6+L0mtDTdKeow76Z8r+p/Sv1X0t9JfK/qHkqQ2P1LxFf1vzh+K88ecf7Q4/3ftB4f/BgIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAnMbHwd6wAcyZ7gE2S3b0RfrHi/7P9C8X/XeS1NowK+kx/sn5J4vzv6d/t+i/kKTWhtLfP2JcpF++x2ADmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmMM9gDlsAHOme4DS/6cr+ihJrQ2nS3qMX3N+6f/7FX0r/fWifyAt/z7ACn7/sxVf0T/n/CvF+W/ZAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOZwD2AOG8Cc6R7gVMmO/i39E0X/hyS1NsxLeow9/dL7AhHj9L7A1aK/K2npe4bWhjvF+S9zfvmegw1gDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDvcA5rABzJnuAS6U7Oh76W8U/f30Lxb9D+nfLvqv0l/2fYLS9xUo+vR9BeeL/sf0S/cMir7LBjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHewBz2ADmTPcApe+fV/Sd9MufR6d/v+g/k5Z/X0Btfq04/03Of1ic/yTnHyvO/5XzS/ccEeMeG8AcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAc7gHMYQOYM5Ok1obrFTlifC1JavPSe/eKPr13f6nov5ek1obNkh7jIv2bRX9b0ireByjNV/RtSWpteFDSY3zKBjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHewBz2ADmTPcA9ypyxPhc0ire239U9B+nf6bof0m/Ff1If63oH0rLv2/Q2rBe9A/YAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOZwD2DOP0dk/daRPyk+AAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CC8937BBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABkUlEQVR4nO3awQ3CQBAEwT1EHJB/WJDIkYOFBHZX/U/+tPbjWXu/9pB1n5mZ9Tz2er/G+3O/vx17yVUIIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNA3PI7uM0FiLMHiL93AeIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgzh4gzgWIsweYmbUex57v91e+bw/AzwggTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcPUCcCxBnD/CF92feE7gAcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBBnDxDnAsT9xR7gzP/Tz/7eBYgTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOHuAOBcg7i/2APYE9gD8iADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcTZA8S5AHGX2AN4bw/AQQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBBnDxDnAsTZA8TfuwBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEGcPEPcB7Emn1h2zBaIAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x1CC8937BBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADGElEQVR4nO2dyWoVURQAz9Vs4oARNcGpnyjO6ELw/z9AcKE4o9htBhIVE6Jmoxw3t3/gvKysqn1xX0JxNn36dsscMwTLSkREtMWVkp3jdkREa8OipOc0dv9s0T/s/o2i/zkiItriZMWPHP92f7XoH0VEtDZcLek5bfXzS/+/yPHwREmU/wYDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAaT4OZuMEgDPvA9wq2Tl+7P5a0d/v/s2i/6n7K0X/T/cvFv1v3X9U9F9GRLQ2rJf0nPa6f63obzoB4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACO+wBwnABwjmUfoLWh9H585nTUz39YPP9V90vv10eOWxHHcj/Bsn//pYofOX7t528Uz991AsAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHPcB4DgB4Mz7AEs9j462uFD0v0dEtDaUvleQOc3fKyj9/sxpfp6+7H39pe8lRI7z9xJK+xiZ03w/Q/l+BScAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcBxHwCOEwDOvA9Qum8+ctzsful5fuS43f3zRf9H9x8X/Rfdf1D0X3f/VNH/3f3LRX+n+/eK/lsnABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAcR8AjhMAzrwPUH6e3P07Rf99958U/ecRx/J+/f3i+W/6+XeL57/r558rnn/Qz18rnr/vBIBjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOO4DwHECwFmJiGhtuF6RM6cvEXEc7+cve9/+eknPaa/7Q9GfIiKiLc5U/MjxZ/eX2sdobbhd0nP64ASAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADjuA8BxAsCZ9wHKz5MjYun366Mtnhb9Z93fKPq73V8t+kfdP130f0VEtDaUvheQOe10v3S/QOZ04ASAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADjuA8D5B4dP+9ZVfiSQAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# New model\n",
    "board = Board()\n",
    "model = Model()\n",
    "learning_rate = 0.3\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Render model before the training\n",
    "print(\"Q_matrix of initial state, before training:\")\n",
    "q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "render_q(q_pred.tolist()[0])\n",
    "\n",
    "# (Action, Reward) container for each action\n",
    "history = []\n",
    "\n",
    "# Populating the history with every possible move\n",
    "for i_action in range(65):\n",
    "    # Reset the board\n",
    "    board.reset()\n",
    "\n",
    "    # Predict an action\n",
    "    a = i_action\n",
    "    encoded_a = encode_action(a)\n",
    "\n",
    "    # Perform the action in the game\n",
    "    s, signal = board.step(encoded_a)\n",
    "\n",
    "    # Process the signal\n",
    "    r = reward_from_signal(signal, board)\n",
    "\n",
    "    # Add the record to history\n",
    "    history.append((a, r))\n",
    "\n",
    "# Q Learning matrix for the initial state\n",
    "target_q = torch.zeros((65,), dtype=torch.float)\n",
    "\n",
    "# Add the reward and action for each game in history\n",
    "# NOTE: ça overwrite si y'a plusieurs valeurs\n",
    "for (a, r) in history:\n",
    "    target_q[a] = r\n",
    "\n",
    "print(\"Target Q matrix:\")\n",
    "render_q(target_q.tolist())\n",
    "\n",
    "# Toggle on train mode\n",
    "model.train()\n",
    "\n",
    "for i_batch in range(1):\n",
    "    # Compute loss on the difference between model output and target_q\n",
    "    q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "    loss = criterion(torch.tensor(target_q, dtype=torch.float), q_pred)\n",
    "\n",
    "    # Let the optimizer do the backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Render model after the training\n",
    "print(f\"Q_matrix of initial state, after training:\")\n",
    "q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "render_q(q_pred.tolist()[0])"
   ]
  },
  {
   "source": [
    "## Troisième étape : à combien de coup est-ce que l'agent \"comprend\" le premier état ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAQAwAQRX7sP+yrOTs4RAO3Zl/II8ln+xj3GMj61i9AGsJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLhz9QKv2K+5uXG/u8cHuQBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEPePb6Cv3jQXIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQ9ca8IwkJKI38AAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D7F0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADQklEQVR4nO2dv6uOcRiH769OYpB0TIbnLWIxUPJjQKSc7E42pSwMinLEdCZyFGVgUcomdp1TIgx+pBgs5NTzDGdy0slAlttw7vcf+Iw+17Vf3d/h6l7eu+dtmX0G2DIREdFad1qRM4dH5V8T/evlHxD9txER0UYzih/Zz5W/W/Q/RUS01p2U9Bye1vy94vwPNX+TOP/nGmkw/DcQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOY0fg72hg1gzvgeYKMiZw4rERHRRs+l6dkfq/mT4vzlmi+9P7JfqfmdOH+o+U/E+dPlL4r+1vIPif5rNoA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA53AOYwwYwZyIiItpoSrKzny9/s+j/KP+G6F8tf63o/42IaE06B4jMOgdo3azor3pttE97QP++fPn7CGwAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAc7gHMIcNYM74HuC8ZGd/r/zron+t/CXR3xIR0Vq3X9JzeFf+tOivfhegjdYpfmT/p+ZvEOf/Kv+S6N9mA5hDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZjDPYA5bABzxvcAC5Kd/fHytenZR/lHRP9l+dtE/3v5e0T/Y0REa90rSc/hcM0/Ks5/Uf5B0X/DBjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHewBz2ADmjO8Btkp29ovlnxL9xxERrXVN0nPI8qX3Zw6L5Z8T/fvlHxf9hfLviP7F8q+I/k02gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjBnfA9wVrKzf1D+Q9E/ExHRWndX0nO4UP6s6M+Wv0v0P5c/J/oz5U+J/nz5/F8AaBCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJzxPcBOyc7+S0REa90tSc/hcs0/Ic5/Vv560f8dEdFat0XSc1gqf7vofyt/h+h/LX9S9JfZAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOZwD2DOP9eoAeUG11RhAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 11\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DFD0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaElEQVR4nO3ZwQmAMBQFwSj2Yf9lWUnsQYSIO3MPvMOSy9/mvOYg61g94BO289m7eb27Y4F99QDWEkCcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDjXwDF+cdV7yg8QJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADibo/dCMInf5LuAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 11\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADSklEQVR4nO2cv8uWZRiGz1uEHNSx+ECfN3GRtgYlEnFR8mtIBCcXF8FFE1GJMFBBEVEJfyyCS0tTIDr4A1vi4xPRoS1aop5H4cPGatDpbvB6/4HTzfM49uO93uHgWp6Lu/U+dkEsqyWptWG7I/c+LZd/0vSvlP+p6f8qSWqzs46vPp4tf9H0H0hSa8M+S+/TnZq/05z/S83/wJz/ZpU1GN4bCCAcAgiHAMIhgHAIIBwCCIcAwiGAcAggHAIIhwDCIYBwGp+Ds2EDhDO/B1jvyL1P/0iS2uxna3ofd9V8+3t2zf/QnP93zf/InP+q5t8y5x8u/w/T31z+56b/hA0QDgGEQwDhEEA4BBAOAYRDAOEQQDgEEA4BhEMA4RBAOAQQDvcA4bABwlktSWqzvZbdx7vlrzP9f8u/ZPrflG/dE6iPbySptcHT+6TyvzX9i29/YLbV+wPj8/KPm/73bIBwCCAcAgiHAMIhgHAIIBwCCIcAwiGAcAggHAIIhwDCIYBwuAcIhw0Qzvwe4JBl9/F2+WdM/1z5K6a/IEmtDZ9Zep+elr/H9B9KktpsjeOrj6/Lf9f3Db6w9D49YgOEQwDhEEA4BBAOAYRDAOEQQDgEEA4BhEMA4RBAOAQQDgGEwz1AOGyAcOb3AD9adh8PlO9N76PK32L6v5e/w/SXyl80/QeS1Npwz9L79FXN327OX35Xnw0QDgGEQwDhEEA4BBAOAYRDAOEQQDgEEA4BhEMA4RBAOAQQDvcA4bABwpnfA2yw7D6+LP9L079f/lrT/0+SWhs2WnqfXpS/3/R/Kt+6R+h9Wir/qumfKP+Y6V9jA4RDAOEQQDgEEA4BhEMA4RBAOAQQDgGEQwDhEEA4BBAOAYTDPUA4bIBw5vcABy27jz+Uf930v5ak1obTlt6nC+UfMf2b5X9s+n+Vf8r0L5dvv/df/lHTv8EGCIcAwiGAcAggHAIIhwDCIYBwCCAcAgiHAMIhgHAIIBwCCId7gHDYAOHM7wG2WXYfn0lSa8N5S+/TdzV/tzn/cfmD6U+S1NqwYOl9Wil/k+n/Wf4npv9b+fb7CGyAcAggHAIIhwDCIYBwCCAcAgiHAMIhgHAIIBwCCIcAwiGAcLgHCOd/i3r/1r+3aMMAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 21\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D2B0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABa0lEQVR4nO3ZsQkDQQwAwTvjOr7/tuxG9D2YhzPsTC5QsCjRnvnMIut1egHOEkCcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBx79MLrLXW3tdPczPfhzfpcQHiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIO4vvoG+eue4AHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSDuBqTNCsLotgORAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 21\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D100>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADSklEQVR4nO2dvUuXYRSG7xMSYRDhlBHvjyIaXSNIoqHW1ojoYzEoIiRsioZoSkIiEnLpg4jW1hwiDKTVMaJ4HyKdJIIkWk5D5/0Hbrfu+9ovj8PFWd7jY2T2CSPLGABEdJOMnNnWy58l/YXyp0h/DQAQoweMj+xvln+J9J8BQER3htKzvan5Z8n5r8sfJ/2tHZRo/hscgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQJ/w5WBtvAHGGe4A9jJzZfgIAYrRCTc9+uvz9pP+9/EOk/wUAIroJSs+2WfMfkvNvlP+N9A+Uf4z0V70BxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxHIA4DkAc3wOI4w0gzhgAIEYXKDv7F+XvJP0/5T8m/Wvl7yb9XwAQ0XF6NpR/i/Tv//sBo9PcL9C/LX+O9Oe9AcRxAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHN8DiOMNIM5wD3CRsrN/Xv5t0r9X/g/S3wsAER319/GZbbX8o6T/EQAQo12Mj+x/lz9N+isAENEdofRsn7wBxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxHIA4DkAc3wOI4w0gznAPsETZ2c+Uz03PHuWPk/5W+VdI/0n5V0l/EQAiupeUnu18zT9Fzl8u/zjpf/AGEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxfA8gjjeAOMM9wD7Kzn6j/JOk/678g6T/FQAiuklKz7ZePvU9PrMtl7+t9wUiugXSny3/Ouk/8gYQxwGI4wDEcQDiOABxHIA4DkAcByCOAxDHAYjjAMRxAOI4AHF8DyCON4A4wz3AOcrO/lX586Q/BwAR3QylZ1sq/wLpvyh/gvQ3y79M+k/LP0H678un3jfIbIveAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgju8BxPEGEGe4B6C+RyP74Xv0HUrPdrfmb/d9Afq9fACI6Kj3ETLbRvnUP0zIbH35U6S/Vv5h0v/sDSCOAxDHAYjjAMRxAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4vgeQJy/RVT91irc68IAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 31\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAQAwAQRX7sP+yrOTs4RAO3Zl/II8ln+xj3GMj61i9AGsJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLhz9QKv2K+5uXG/u8cHuQBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEPePb6Cv3jQXIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQ9ca8IwkJKI38AAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 31\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DA60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADTElEQVR4nO2dPY+MYRSG78MWiBAfUZC8U2ioNhpBohEkJDqWH0C1RBQbRDONIFuIsBU/YC2dhATRSBCNbEWjeJ+EQnyECBo5ij3zB+7p3PfVX3OmuHKaOXkmMvuEkWUCABCDdZSd/TcAiOimKT3bXPnbSP8dACAGtxgf2Z8u/wrpXwSAiO4wpWd7WPNnyfkz5W8m/Y/LKNH8NzgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxHIA4DkAcByBO+OdgbbwBxJkAgIhuFSNntl8AgBi8pqZnv7P8g6T/uPxJ0l8EgIhuNaVn+1nzL5PzL5XPbeHso/zdpP/SG0AcByCOAxDHAYjjAMRxAOI4AHEcgDgOQBwHII4DEMcBiOMAxPE9gDjeAOKM3gc4RdnZ3waAiC4oPVvW/Lvk/OPlryX97wAQ0XF6NpR/hvRvLn3AYIr7Av1C+RdI/6o3gDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI43sAcbwBxBndA5yg7Ozny6d/jy7/C+lvAICIbg+lZ3tR/grS/wMAiMFKxkf2v8s/S/o3yl9P+l+9AcRxAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHN8DiOMNIM7oHmDc/6/npme/pEe3htKz/aj5Q3L+sPxrpH8eACK6OUrPNl3zj5DzH5S/n/SfegOI4wDEcQDiOABxHIA4DkAcByCOAxDHAYjjAMRxAOI4AHEcgDi+BxDHG0Cc0T0A+WB+Xw/mD3aR/qvyt5L+ewCI6DZSerbP5e8g/TflT5L+YvnXSf9c+dT7Dplt3htAHAcgjgMQxwGI4wDEcQDiOABxHIA4DkAcByCOAxDHAYjjAMTxPYA43gDijO4BjlJ29vfLH5L+EAAiumOUnu1e+QdI/0n5y0n/b/mHSP9R+ePeI5wk/TveAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgju8BxPEGEGd0D7CPsrN/BgAR3QylZ5ut+XvJ+c/LnyL9BQCI6DZRerZP5W8h/Q/lj/u+wHbSf+sNII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDi+B5AnH8bW/3WkgXIygAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 41\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZUlEQVR4nO3ZwQnDQAwAQdukj/Rf1lUi93AEDrIzf4Eeiz66Z9ZcZD2nF+AsAcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBD3Ob0AP3B/9+ZmuQB1AogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEOcb+A9mbY+6AHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSDuBeIdCMJgx7R0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 41\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D2B0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADTUlEQVR4nO2dz4uNcRTGn6NhsrIxC9H3xkLEoCmlLIW9X8VSMpqiiZQ/QYkmajKSJeXXHs1SKTVhiCzofSOLsbHSsDgWzv0HHjvP89l/7nkXn87mnvveyOwSRpYRAEAMdlF2dq8AIKJNUnr2c+VvJv2PAIAYXGV8ZHeh/DnSnwSAiHaA0rN/WvPvkfOPlz9O+osrKNH8NzgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxHIA4DkAcByBO+OtgbbwBxBkBgIi2mpEz+58AgBg8pKZnd6T806R/q/wJ0l8AgIg2SunZL9f8KXL+bPmUjuxQ/h7Sf+ENII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDi+B5AHG8AcYbvBzhF2dndBoCItorSs/9V8++T84+Vv4b0fwBAROP07FH+GdK/+fcDBoe5B+gelT9N+jPeAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgju8BxPEGEGd4D3CQsrN7Uv5J0r9T/gfS3wIAEW0vpWf/vOavJ+d/LX8l6f8u/zzpXyt/O+m/9QYQxwGI4wDEcQDiOABxHIA4DkAcByCOAxDHAYjjAMRxAOI4AHF8DyCON4A4w3uAs5Sd3Y3yl0h/DAAi2iZKz/5Tzb9Czr9Y/nXSPwcAEe0SpWd/ueYfIuc/Ln8f6c97A4jjAMRxAOI4AHEcgDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOL4HEMcbQJzhPcA2ys7uXflbSf99+eOkvwgAEW0tpWf/vfwNpP+l/AHpd+XPkP50+ftJ/5k3gDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI43sAcbwBxBneA9C/Ly9/kvTnACCiUfMz+/nyd5P+SwBADEYZH9kt1/x/+r+CiLaR9D+Xf4L073oDiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI4wDEcQDiOABxHIA4vgcQxxtAnOE9wFHKzu4BAES0aUrPfqbmT5DzF8qfIv1ZAIhoY5Se/VL560j/W/k7Sf91+TtI/403gDgOQBwHII4DEMcBiOMAxHEA4jgAcRyAOA5AHAcgjgMQxwGI43sAcf4ABUz71lly9sIAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 51\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D4C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAMBQFQRX7sP+yrCT2EISgO3MPvMOSy9/HuMdG1rl6wCv2a+7duN/d8UHH6gGsJYA4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHH/uAa66k3zA8QJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLgHh+wIwmtjefoAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 51\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADO0lEQVR4nO2cv+vNcRSHX0ffsIjC+rlFiaQQyiIGEynyM4uQZLDJiFE2gyRkkZ/5lpgMZFEIJZGiPp8VRRYM3gbn/gPna/J6nv2553Z7Pme5595orW8CWyYkSTHaVrJbf0eSIrr9Jb0Nl9NfWPQ/SJJidLriq/XH058s+lslKaJbX9Lb8CjnvyzOX5H+lqJ/d1pJhP8GAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMCc4Otgb9gA5kxIUkQ3vSK3NvySJMXoYml66w+mf7Lon0x/ddF/ln7tQWj97/R3F/3r6Zd0tV7pbyz6D9gA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJzx/wMcLdmtPytJEd3Mkt6GHzn/SnH+vvRnF/1vkhTR1fQ2KP19Rf/K3xcY7am9gf5a+keK/jk2gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjBnfA+wrmS3/nH6O4r+rfSfF/1VkhTRrSnpbXia81cW579IP4p+S/9U0T+R/qGif4ENYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA73AOawAcwZ3wPsLdmtv5r+16I/R5IiukUlvQ3vc/5kcf7W9C8V/QOSFNFtLultuJfzp/r5byr699kA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJzxPcDakt36J+kvKPof05/S7/MjusUlvQ3v0p9R9H+mP6/of07/TNE/lv6Sov+WDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDmsAHM+Vf3ALuK/g1JiuiWl/Q2vEp/SvcAitGciq/Wf/0X8yO6WUX/e/obiv5DNoA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA53AOYwwYwZ3wPsLNkt/6mJEV020t6G27n/GXF+a/TP1z0z0tSRDe/pLfhU/pzi/6X9JcW/TfpLy/6r9gA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYM4fwiL61hhJ+VUAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 61\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQmAQAwAwVPsw/7LspKzBxFO3Jl/II8ln2xzXnOQta9egLUEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNA3LF6gU/Yzmdz83p3jwVcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI8w0c4xdfvadcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQdwO0DQjCJ5xeEwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 61\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D4C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADSUlEQVR4nO2dv6vNcRjH3x9dyY8UBil9j8EgC9fAapNIlBhutyxik5RBt6RkUJKNLEoGUiSS7a4MLosMBt9vSgaU/EjkMXjOP/Cczfv12l/nOcPrPMv36XtaRB8CW6YkSW00W7KjvylJrXVHSnoMN9LfWPTfSJLa6FzFV/Rn039Q9PdJUmvd1pIew4ucXxqv6JX+yaJ/eVFtMvwvEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmNB4He8MGMGdKklrrFlfkiOGXJKmNrpWmR38s/QtF/0z600V/If1VRf9z+ruL/uP0Pxb9NekfLvq32QDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmcA9gDhvAnPH7AU6V7OgvSVJr3fKSHsO3nH+3OP9g+iuL/hdJaq2r6TEo/Zmif+vfB4yO175AfzX9o0X/OhvAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHO4BzGEDmDO+B9hesqN/lv6eov8o/Unf1196oB8x5AP90f7i/Ps5vxXnR86fK84/P6nPBjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHewBz2ADmjO8BDpXs6O+k/6PoL5Wk1rrSPULEML5HeFmcvyX9W0V/RpJa6zaX9Bhe5fzZ4vyb6R8o+vfYAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOZwD2AOG8Cc8T3ArpId/ZP01xX99+nvLPrzktRat6Okx/A05y8pzv+Z80s/pIjhT/oXi/7p9FcU/a9sAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzCHDWDO+B5gumRHv5D+3qL/UJr8ff+TPA+XJLXR2oqv6D/k/PXF+e/Snyr6v9PfUPTfsgHMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDM4R7AHDaAOeN7gBMlO/orktRat7OkxzCf8zcV579O/3zRn5Ok1rrVJT2GTzl/WXH+95w/0f8NtNZtK/rP2QDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmcA9gzl//3/nWbuo54wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 71\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D5E0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABa0lEQVR4nO3ZsQkDQQwAwTvjOr7/tuxG9D2YhzPsTC5QsCjRnvnMIut1egHOEkCcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBx79MLrLXW3tdPczPfhzfpcQHiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIO4vvoG+eue4AHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSDuBqTNCsLotgORAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 71\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADR0lEQVR4nO2cv6uOcRiHP18dv0Upy1HPe0opCwvFYJcMCpGVgeUoTMfsTCgWBlY5oQyS3UAdC4tS6jxPOYtSxPGr3Ab3+w/cx+RzXfv13u9wvffy3s/TIvoQ2DIhSWqj6ZId/Q1Jaq07XtJjmEt/qugvSJLa6HTFV/S3039c9A9JUmvdlpIew4ecXxqv6JX++aJ/bUVtMvwvEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmNP4O9oYNYM6EJLXWrazIEcMvSVIbzZamRz/zj/ydRf91+pNFfzH93UX/Zfrvi/7W9E8W/btsAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzCHDWDO+P0A50p29NclqbVuY0mP4XPOv1KcfzH99UX/qyS11tX0GJT+0aL/4O8HjE7VvkB/J/3S+xkU/RwbwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBzuAcxhA5gzvgfYUbKjf5P+vqL/PP0bRX9aklrrVpf0GH7k/GPF+fdzfivOj5x/uTj/UvozRX+WDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDmsAHMGd8DlJ5vV/Tj59vfFv3tktRad6Kkx3Av5z8pzj+Y/q2ifyb9tUX/W/pHiv7D9A8X/UdsAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzCHDWDO+B7gQMmO/mn6m4r+p/T3FP15SWqt21/SY3iW85f7/dcV/SVJaq2bLekxzOT8NcX539kA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJzxPcC2kh39u/T3Fv0X6a8q+j/TX+7z+ZNFfzH98v/x6S/rHqG1bkNJj+ELG8AcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAc7gHMYQOYM74HOFuyo78pSa11u0p6DK9y/lRx/kL6F4r+VUlqrSs93x8xLOX8zcX5H3N+6YcYMfxOv/R+hYhhng1gDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDvcA5vwBR9Dy1q6P+6QAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 81\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZklEQVR4nO3ZywmAMBBAQSP2Yf9lpZLYgwRE3sw9n8NjLzvWmusg6/z6A3xLAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcRdW24Z97tza255nvdMgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI27MNtNX7LRMgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD1hzQjCisnXCwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 81\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D3A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADM0lEQVR4nO2cv6uPcRTHz8ePEgZJGHi+t9ikLpvNYCGDwUwGsihhITeJWJCyiEHMBoNYDDabe0s2yvMwoJsMSKFjcJ5/4P3dvF+v/fU9t+/31Vmec5+W2WeALcsiIqJNrkh29uciIlrr9kt6Do/L3yz67yMiok2OKX5kf6f8p6K/t/wm+lm+pEf2Uf5p0b++RJsM/wsEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDmNx8HesAHMGe8Blkl29r/Ln+qeINrkmuifKX+X6L8of0b035W/XfRflf9b9Mff77Do32cDmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmMM9gDlsAHPG58kXJDv7ixERrXVrJD2HrzX/hjj/VPkrRP9nRERrnabnEOXvE/0n/z5gclL7A/qb5R8Q/UdsAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzCHDWDOeA8wK9nZL5S/U/Rflj/tPcBK0f9R/gnRvxUR0VonvV8hcxjfr3BXnH+0/EuiP8cGMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMId7AHPYAOaM9wDHJTv72+V/Ev0NERGtddLz7Mxhrua/FudvK/+e6B8pf0b035V/UPQfln9I9B+wAcwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMzhHsAcNoA54z2A/Dy5/LWi/6X8PaL/LCKitW63pOfwvOZvEee/LX+d6C9GRLTWnZf0HC7X/PXi/M9sAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzCHDWDOeA8wkezs+/JnRX+h/FWi/738TaL/ofytov+m/I2i/7H8ab//1aL/jQ1gDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDvcA5rABzBnvAc5KdvZXIyJa66T/j88cFmv+DnH+fPm3Rf94+ctF/1f5075fYKno/4mIaK2Tvr/MYZ4NYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA73AOb8BbFu7Na9qpiAAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 91\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DA60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQnDQAwAQV1wH+m/LFdy7sEELrAzf4Eeiz5ae997yPqcXoCzBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQNx1eoGZmVnfd3P7/u0eQS5AnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcT9xzfQV+8YFyBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD301QjCs20YYgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 91\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D7F0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADI0lEQVR4nO2dscuNcRSAz08GC1kQ5X6URJSUyWL4lEUMFpMMVhRRislXinzlsxpkshjIohgsJiVFJMX7KsIiFoP6GZz7D5y7eZ5nf+653Z7Ocs+9b+t96CFYlkdERJu7XLL7cCkiorXJgZLex0fpry/6XyIios2drfjRh+vpPyn68+mvLPq/0v9R9Fenf7HoLywrifLfYABwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADjNr4PZuAHgTO8BNpbsPnxK/0rRv5D+YtE/k/6+ov80/R1F/3X6W4r++/RLevQh0r9a9M+7AeAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjvcAcNwAcKb3AAsluw8XIyJam6wq6X38mfNnvSdYUfR/R0S0NqnpfYz09xf9x/9eYO5E7Q0Mt9I/XPTvuwHgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI73AHDcAHCm9wDbS3Yf3qS/rei/Tb/8f/fpry3639I/V/SvRUS0Nlle0vv4J+ffKM4/nf5S0T/lBoBjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAON4DwHEDwJneA5ws2X24mf7nor8hIqK1yZ2S3sdjOf9Zcf7e9Gf9Pn5P0X+e/sGi/zD9o0X/rhsAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOB4DwDHDQBneg9wpmT3YTH9TUX/Y/rzRf9JRERrk0MlvY8Pcv7u4vwX6ZeelxB9+BkR0drkeEnv4+2cX3zgwTC6AeAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjvcAcNwAcKb3AOtKdh++pj/r8wI2F/0P6c/6vIOtRf9d+huK/uf0Z/38vAeQGgYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4DjPQAcNwCc6T3AqZLdh6X0Z/p9fLS5nUX/Vfr3iv6R9NcU/e/pz3pPMNM9RmuTXSW9jy/dAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAx3sAOH8BWdPr1kLhGxoAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 101\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD30>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZklEQVR4nO3ZywmAMBBAQSP2Yf9lpZLYgwRE3sw9n8NjLzvWmusg6/z6A3xLAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcRdW24Z97tza255nvdMgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI27MNtNX7LRMgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD1hzQjCisnXCwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 101\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DA60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADOUlEQVR4nO2dzYuOYRSHzy0LSVM2eks970TJR1aSkoUok/wBFqzsUBqZTDYWNhoRKexmNRb+AGnUyEJKspKPFM39lHqzUZLsbgvnyf43O7/r2l9zZurqbO4zPaW12gJsWR8REWV8S7JbvRQRUUp3RNJb/yz9TvT7iIgo4/uKH62eS38i+qP0R6I/Sf+H6E+lvyD68+skEf4bCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCs/B3rABzBnuAbZJdqtf0r8n+ufTvyH6l9OfEf3l9HeI/qf0pXuGaHW4Z5D0aDXSl+8h2ADmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmcA9gDhvAnOEe4KZktzoXEVFKt0nSW/8z518V519Lf4Po/46IKEV8zm/5nF+6o6K/8vcHjK9ov0C9nr58D8EGMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMId7AHPYAOYM9wC7JbvV9+lPi/5q+rOifyf9PaL/Lv2Lon87IqKUbqOkt/5Xzn8gzj+b/kPRP8UGMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMId7AHPYAOYM9wCzkv3vPX5V9KcjIkrpHkt660/k/Ofi/MPp3xX9C+mfFP1H6R8X/Sfpnxb9JTaAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOdwDmMMGMGe4B5iX7FYX0j8o+i/TPyb6TyMiSumk7x201s/l/P3i/Nfpj0R/EhFRSie957fWL+X8XeL8D2wAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAc7gHMIcNYM5wD7BFslv9lv520f+c/gHRf5X+IdF/kb78np7+VtH/mv5a//4Z0V9mA5hDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZjDPYA5bABzhnuAM5Ld6mL6a/r/+CjjfaL/Jn3pewPR6vC9gU70+/T3iv7b9HeK/seIiFK6zZLe+u9sAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHO4BzDnD7x769bbKcFHAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 111\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D4C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZklEQVR4nO3ZywmAMBBAQSP2Yf9lpZLYgwRE3sw9n8NjLzvWmusg6/z6A3xLAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcRdW24Z97tza255nvdMgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI27MNtNX7LRMgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD2ydwjC9Rsj1AAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 111\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DA60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADK0lEQVR4nO2dvWpUURRG9xEDPoEBI3cEmwiCiiJWWkSM1toFJFpZCBb+oI0EG8WfQrCw0iCk01ojptBKJKKCYBrBczFCfAIhxbFw3xf4pvNbq1+zh2Gxm7uHW1qrLcCWrRERUUYPJLvVyxERpXSHJb31H9LfIfq/IiKijBYVP1qdT39d9KfS3y76v9OX9Gg10n8o+pe2aJPhf4EAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMKfwONgbNoA5wz2A9kC61Zr+kujPpX9L9G+mPyv6y+lPi/5a+pOiv5H+huhPpi///mwAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAc7gHMIcNYM5wD7Ag2a0uRESU0k1Ieus3c/4Vcf799LeJ/p+IiFI6TW99pH9I9Ff/fcDoqvYF6r30Z0R/hQ1gDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDvcA5rABzBnuAXZJdqs/0h/3//EXRf9R+vtE/0v610X/TkREKZ30voDW+uF9AY/F+RfS/yT6B9gA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJzhHmDc5/HvRf9IREQp3WtJb/2JnP9WnH8s/duifyP986L/JP3Tov8i/XnRX2QDmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmMM9gDlsAHOGe4Brkt3q3fSPi/6b9OdEfykiopTuuaS3/kzO3yvO/5r+lOivR0SU0p2U9Na/yvnS+wqi1VU2gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjBnuAfYLdmtfk9/p+j/TP+o6L9Lf1b0l9PfI/rf0h/3fQnjfv9Tov+SDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDmsAHMGe4Bzkl2q0/Tnxb9tfRnRH8l/Weifzb9kejX9PeL/uf0D4r+x/QnRH+TDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDm/AWpx+rWvl0zGwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 121\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZklEQVR4nO3ZywmAMBBAQSP2Yf9lpZLYgwRE3sw9n8NjLzvWmusg6/z6A3xLAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcRdW24Z97tza255nvdMgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI27MNtNX7LRMgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD1hzQjCisnXCwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 121\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D790>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADLUlEQVR4nO2cTYuOYRiGr3siWVkIm5nnLbOQjcWUlIURG5IsfBSbyUf5AYqFmIYsKD9AGZoN5WMhiQ0ZCyU1CxtZjHqemQ2ysJLU3Bau5w+cr5XzOPbHe72Lo2tzXz2l1rYG2LIqIiLK4IZk1/Z8REQpzZik124p/VHRX46IiDK4rfhR2zPpr4j+SPqbRf9z+pIetY30H4r+0RFtMvwvEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmFJ6DvWEDmNPfAwz7nn1f9I+nf0n0r6Y/Kfrz6Y+L/mL6G0X/a/o/RX9t+k9E/xAbwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBzuAcxhA5jT3wNcluzaXomIKKWRQqq1W8n50+L8mfTXiP6viIhSGk2vXaQ/IfoLf39gcE37A+3F9HeL/ms2gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjDnX30fYIPof0v/rOjfSn+X6L9J/6To342IKKXZJ+m1e5HzH4nzj6S/KPrjbABzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzuAcwhw1gTn8PcEqya3sn/beivzMiopTmuaTXbn/OXxDnT6R/TvRvpn9B9K+nf1D0n6Z/QvTvsQHMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwhwDM4R7AHDaAOf09wIxk13Y6ffk9Ov0p0Z+LiCil+SHptVuX87eJ8z+kv0n0v0RElNKslvTa/c75O8T579gA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5nAPYA4bwJz+HmCrZNf2Y/pDvYdHGewR/VfpHxD9Z+mPif5S+ltE/1P6p0V/Nv1jov+ADWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDmsAHM6e8BDkt2bR+nP+w9waToz6c/J/pT6Y+K/nL620X/ffp7Rf9l+utF/zsbwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBzuAcz5A9tv6tb4/EmuAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 131\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAMBQFQRX7sP+yrCT2EISgO3MPvMOSy9/HuMdG1rF6AGsJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLhz9YBX7Nfcu3G/u+OD/ABxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEPePa6Cr3rQHIQUIwnQ2/dwAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 131\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D190>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADI0lEQVR4nO2dsYvPcRjHn49ETjKYGL4/iwxyxUX5A47khl+ySCSLyeCK5ZZbbqHOYLJIJIt0w0ncH6DoqJNBFp/vwGSQnFg+lueb/e0m79drf/Usr57l8/y+v9JabQG2bI6IiDKak+xWFyIiSul2SHrrv6e/R/Q/R0REGd1W/Gj1Svq/RX9L+kdE/3X6kh6tRvr3RP/iJm0y/C8QgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYUnoO9YQOYM9wDHJDsVt+nf0P0r6c/K/qL6Z8U/WfpHxT9d+lrD/qt1vR/iv629N+K/iE2gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjBno74PUCS99S3nL4jz59LfKvq/IiJK6X5Ieuu3py/dE7TWD/cENxU/Wr2W/rTor7ABzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzOEewBw2gDnDPcBuyW71ywb550X/Qfozor+c/mXRvxMRUUp3RtJb/zjnr4jzp9NfF/0JNoA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA53AOYwwYwZ7gHOCfZrT5M/6XoH4uIKKVbk/TWT+b8VXH+VPqXRP9u+vOiP5/+CdF/nv5Y9JfYAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOZwD2AOG8Cc4R7glmS3ejX9segvpT8r+osREaV0mt76yPlT4vzV9HeJ/teIiFK6CUlv/XrO5/8CQIMAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMId7AHPYAOYM9wCHJbvVN+n/03t4lNEp0X+a/lnRf5T+PtH/mP5+0f+Q/gXRv5/+WPT5PoA7BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA53AOYwwYwZ7gHGEv239/3HxX9V+kfF/0X6S+L/kz6e0X/U/qTor+W/mnRf5L+TtH/xgYwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzCEAcwjAHAIwh3sAc/4A9Zfq1hQVQroAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 141\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQmAQAwAwVPsw/7LspKzBxFO3Jl/II8ln2xzXnOQta9egLUEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQNyxeoFP2M5nc/N6d48FXIA4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiPMNHOMXX72nXIA4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQdwN5oAjCllmO0wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 141\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D3A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADK0lEQVR4nO2dsYvPcRjHn48uZSAimX6XKNINBotSdItDUqcblEUnBgsLiZIisbjFQC6LMlyuJJzlopTFYLhEkT7fSSJiUFIfg+f7D7yZvF+v/dWzvHqW79PnW1qrLcCWoYiIKMNnJLvVi+kvEf0fERGlDFZIeuu+5Pwpcf7x9L+L/tL0t4j+i/Q/i/7K9B+K/u5Fkgj/DQRgDgGYQwDmEIA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOYXPwd6wAczp7wFGJLvVhfRviP6R9I+J/rX0x0R/Lv2tov88/c2i/zJ9SY9WI/23or+eDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDmsAHM6e8BJiW71en0i+i39C+I/tn0F4v+z4iIUgbTkt66yfTXiP6HiIgow+cVP1o9l/6o6M+zAcwhAHMIwBwCMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMzhHsAcNoA5/T3AQLJb7f6Rf1D0b6e/TfSfpX9J9E9HRJQy2CXprXuU8x+I8/ek/030l7EBzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMIcAzOEewBw2gDn9PcAhyW71Vvozoj8REVHK4Kakt+5wzn8tzt+Y/gnRv5r+SdG/kv5O0X+c/l7Rv88GMIcAzCEAcwjAHAIwhwDMIQBzCMAcAjCHAMwhAHMIwBwCMId7AHPYAOb09wCzkt3qePoHRP9O+qdE/3JERCni8wTtz/MEUYZHxPkL6a8S/U8REaUMhiS9db9y/nZx/lM2gDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAOAZhDAOYQgDncA5jDBjCnvwfYJNmtvkp/ueh/TX9U9OfT3y/6d9PfIPpv0l8n+u/SPyr619OfEP0ZNoA5BGAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA53AOYwwYwp78HGJfsVmfT3yH6T9IfE/259KX/DUSr/f8G1or++/T/9n2BfaJ/L/3Vov+RDWAOAZhDAOYQgDkEYA4BmEMA5hCAOQRgDgGYQwDmEIA5BGAO9wDm/AbmA+jWfFkKVgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 151\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DF10>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaElEQVR4nO3ZwQ2AIBAAQTT2Yf9lWQn2oCZqduYPx2PD55Y5jznI2t5+AGOMZb92bh63R6+3b+DXBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIM428Ase2Opd5QeIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxJ5+/CMLKmhB+AAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 151\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D3A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADBklEQVR4nO2dsavNYRiAv0+3WC4DdU3ndEu5YlQW401chPWOQkmyyKAkKYMskhQy3hXhku5oUUZylbr9zuQWAxZKfQbv7x94z5k8z7M/vWd4epfz9v1qa10rgmWqlFJKHZ5M2a17FP7WpP8t/I1J/3f4V5L+9fB/Jv3p8Hcl/Y/hryf9mfBfJf2DG1Ki/DcYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwATvXvYDZuADj9PcDOlN26T+E/TfrHwh/3HuFw0n8R/v6k/yb8uaS/Gv5a0p8NfzXpz7kB4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACO9wBw3ABw+nuAcym7dXfDn0r6f8K/k/TPh78l6X8vpZRaB5dTehvdCH866f97l6AOr2X80rqr4e9N+u/cAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAx3sAOG4AOP09wLaU3bqv4W9P+l/CX0j6y+HPJ/2V8Mf63kCtgwMpvY1ex/zl5PyF8FN6aZ0bgI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgeA8Axw0Ap78HOJ6yW/ck/KWkv1hKKbUOLqb0NroV898m5+8L/2zSvxf+paR/M/wjSf95+IeS/ks3ABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHA8R4AjhsATn8P8Dhlt+5E+KeT/oPwLyT926WUUusgp7dRifk7kvM/hz+T9NfD35T0f4Wffl/BDQDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcLwHgOMGgNPfA+xJ2a17H/7mpP8j/KNJ/1n4Z5L+/fBnk/7ahPxxf/+ppP/QDQDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcLwHgOMGgDOp7wXMJ/2VCc0f63sFpQ6HSb8Lf3fS/xD+YtJfCj/5QEI3cgPAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABzvAeD8BeRl5tZUO31QAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 161\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQmAQAwAwVPsw/7LspKzBxFO3Jl/II8ln2xzXnOQta9egLUEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNA3LF6gU/Yzmdz83p3jwVcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKI8w0c4xdfvadcgDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQdwO0DQjCJ5xeEwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 161\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DBE0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADCElEQVR4nO2dzYtOYRiHnyO2ygZF86asfPwJVhOSfGSjSJmJFZvJSjazkZVmw4pmlCgbMZLQrPwJPlZKZ6KwUbbUsZj7/AO/d+e6rv3Vc07v1b05d8/bDUM/NMGyubXWWjeZj+yhXy5/Evp9+dtC/1f5N0L/ZvmR3oaNx2/dZDb018r/G/rj7/c09M9sikT5bzAAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGACczs/BbJwAcMbvydN+z38X+ofKnwv9lfLPh/6j8k+G/mr5h0P/bfnfQ39n+R9Df78TAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDguA8AxwkAZ9wHuBDZQ/+w/C2h/6f8+6F/qfy9of+5tda6buZipA/rD+r8ad9/KfQXyt8X+p+cAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAx30AOE4AOOM+wPbIHvqf5c+E/nr5R0L/TfnHQ/9l+ddD/1ZrrXXdzLFIH9Zf1flr4fmz5cf/N+AEgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA47gPAcQLAGfcBTkT20L8ofzX0T7bWWtfNLET6sL5U5/8Iz99R/nzoL5cfPX8b+vH5T4X+8/LjfQgnABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAcR8AjhMAzrgP8CSyh/5s+Yuhv1j+tdC/3VprXRdeTzBsXE8wzX375U9Cvy9/2vsVTof+MycAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcBxHwCOEwDOuA9wILKH/kP5W0P/d/nnQv9x+VdC/275u0P/a/l7Qv9L+ZdD/175c6G/4gSAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADjuA8BxAsAZ9wGmva/+aOi/Ln/afYA+9CflT7sPcTD035d/NfTvlL8r9L85AeAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjvsAcP4BTyLl1lAdY8IAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 171\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DFD0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAMBQFQRX7sP+yrCT2EISgO3MPvMOSy9/HuMdG1rF6AGsJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLhz9YBX7Nfcu3G/u+OD/ABxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEPePa6Cr3rQHIQUIwnQ2/dwAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 171\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD30>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADBElEQVR4nO2cv6uPcRxHP4/8mCwGRfkq5G5Y7JKBgXK36w6uRCmiZJFRFimilJtcw2WjGBgkuwXbFer5qqsMFhOGx/L+/gOva3LO2U+f5fRenldPNwz90ATL6tZaa93WE5E99A/Knwr9pfI3hP6P8i+H/rXyv4f+xvL3hf6b8v+E/pryF0N/dlUkyn+DAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4HR+DmbjBYAz2QNsjuyhXy7/bejvLf9U6M+XPx36T8o/GPovy98f+q/L/xD6u8r/FPo7vABwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMc9ABwvAJzJHuBYZA/9o/LXhv7v8m+E/sXyt4X+l9Za67rRXKQP44V6f334/s/yr4f+pfJ3hv5HLwAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwHEPAMcLAGeyB9ge2UP/ufxNof+t/MOh/7z8A6H/qvwLoX+ztda6bnQ00ofx03r/Sfj+dPmR3obeC0DHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcNwDwPECwJnsAVb6v/zHoT/TWmtdNzoe6cP4Yb3/K3x/Xfmzob9Y/lzoL5R/KPRflH8k9J95AeAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjnsAOF4AOJM9wL3IHvrT5d8O/XPlnwn9u6211nWjTB/Grd6fCt9fKn9L6H/9R3685/ACwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAc9wBwvABwJnuA3ZE99O/L3xD6P8o/FvqPyj8b+nfK3xz6y+Wv9Hv+ydC/X/6p0J/3AsAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHPcAcLwAcCZ7gPORPfS3yp8J/cflr3QPMA79Ufkr/T/AntB/V/6V0L9a/s7Q/+gFgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA47gHg/AU3QeXW3a3XZgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 181\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABa0lEQVR4nO3ZwQ3CQAwAwRyijvTfFjRieogiDrEzf0t+rPzxmnnNQdZj9wLsJYA4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOKeuxf4BWudl+Zm3jdv8n0uQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHE+QYe//HVu8oFiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxH4dGCsIAeBLjAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 181\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DF10>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADFUlEQVR4nO2du4tVZxRHvxOmDenCKOEOUZCAKAyksQoEEwyilWB8NGJjocQmA3mUJoFJkxALm5DGJ1gpoqgIVjbCgCKI4Mi5SBzsxFb40uz7D/yuVdZa/WJzYLGbu8+5Q+9jb4JlobXW2rB0KLL7eKn8XaH/oPwPQ/9t+T+E/m/lPwv9beXP+/yR3vrYyj8X+ic+yCbL/wUDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAGfw5mI0bAM7sHmBTZPfxVfn3Qv/L8r8P/d/L/yb0b5a/L/Svl78n9G+V/zD0Py9/LfSX3QBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMd7ADhuADize4BvI7uPl8tfCP135f8a+j+W/2nov2ittWGYRM/f+3T2/Ivh/I3yV0J/tfwtob/uBoBjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAON4DwHEDwJndA+yM7D4+Kv/j0H9d/u7Qv1v+16F/u/zvQv/P1lobhsmpSO/Tv2r+1XD+gfLfhP5HbgA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgOM9ABw3AJzZPcDeyO7jjfLner9/GCYHI71Pr9T8jXD+YvlHQv9C+YdD/2L5X4X+nfLjewg3ABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHA8R4AjhsAzuweYDWy+7hS/i+h/1P5p0P/j9ZaG4ZJpvdpq/mfhPNflr819J+/p/n7Q/+aGwCOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4HgPAMcNAGd2D7Ajsvv4uPzNof9v+cdD/+/yfw79M+VvCf318j8L/aflz/V/BW1YOhr6590AcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHewA4bgA4s3uAk5Hdx7Plx++nl38s9P8p/37of1H+9tB/Uv5y6K+VP+/3GeJ7BjcAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcDxHgDOf6R65dZdpFexAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 191\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D100>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZklEQVR4nO3ZwQnDQAwAQdukj/Rf1lUi93AYQrwzf4Eeiz46Z9YcZH1+vQAPOL97c7OO69lN+DcCiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQ5xv4BrO2R12AOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQdwOnsAjCwEOr5gAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 191\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D220>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADEklEQVR4nO2dv6uOcRiHv49MFptf5UghomQxGUzEKQYxSKcoA6FIGcggBiUKMSjqJAMZnDpOTIYzWaSIUHqO8muzWB/L/f4Dn7O5rmu/uuvt6l6eu+/bDUM/NMGysLXWWrfqaGQP/b3yt4b+6/IXhf7f8k+G/q3yP4b++vK3hf5s+ZHehr6Vfz/0jyzIJsv/ggHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOB0fg5m4waAM7oHWBbZQ/+z/OnQHy//QuhfLn9P6E+Vvyv0Z8rfF/pPy58N/W3lfw79tW4AOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4DjPQAcNwCc0T3ARGQP/WT5i0P/T/m3Q/9E+atD/2trrXXd2IFIH+Ye1/yl4fxf5R8L/bvlbwj9D24AOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4DjPQAcNwCc0T1A/D25/CWh/7v8+f7fwHjoT5d/NfTPtdZa141F7xsMw9zofYMn4fz95f8K/aVuADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOA4z0AHDcAnNE9wO7IHvrn5d8M/VOttdZ1Y6cjfZi7UfO/hfNXlr839J+Vfzj0H5Q/399/Z+i/cAPAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABzvAeC4AeCM7gFmInvod5V/MfQvlX889O+01lrXjWX6MNdq/ppw/pfyN4X+u/JXhP738neE/ks3ABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHA8R4AjhsAzugeYEtkD/2b8peH/o/yD4b+o/LPh/6V8jeG/vvyN4f+2/InQn+y/EOh/9ANAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwvAeA4waAM7oHOBvZQ3+t/D2hP1X+mdC/Xv6r0N9e/tbQf13+fN8HuBr658pfF/qf3ABwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMd7ADj/AMWC5dYXQ7U3AAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 201\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DAC0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABZ0lEQVR4nO3ZwQmAQAwAQRX7sP+yrOTs4RAO3Zl/II8ln+xj3GMj61i9AGsJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngLhz9QKv2K+5uXG/u8cHuQBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEEPePb6Cv3jQXIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQ9ca8IwkJKI38AAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 201\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5DD30>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADCElEQVR4nO2dv6uOcRiHv49sTFZ1jkEURRIWQiILIhaDJGXyK1lEKbJIfk3qJBksRFhEcsSCJIoig+ctq4n5sdzvP/A5Jtd17Vff5eqzPHfv2w1DPzTBMru11lo3eTKyh/5i+RtCf7r8uaH/u/yDoT9V/uvQX1v+htCfLj/S29C38m+F/v5Z2cvyv2AAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4nZ+D2bgAcMb3ABORPfSj8p+G/pbyz4T+ufK3hf7j8teH/svyd4T+w/Lvhf7u8r+E/hIXAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgeA8AxwWAM74H2BfZQ3+7/Dmh/6f8q6F/tPyFof+9tda6bmJ/pA+jW//i/dZNng798+WvCv13LgAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwPEeAI4LAGd8D7Aosof+W/nzQv9X+StD/335m0L/efmXQ/94a6113cS1SB9GR+r9N+H7a8r/GfrzXQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgOM9ABwXAM74HmBXZA/9/fJn+j39RqQPo0P1/tfw/cXlbwz9F+UfCP2b5W8P/Ufl7w39Oy4AHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcDxHgCOCwBnfA8wFdlDf7D8mf7e/cnQv9haa103kenDqNX7i8P3v5a/JvTflD/T/xvYHPrPXAA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgOM9ABwXAM74HmBdZA/9q/IXhP6P8veE/t3yL4T+qfJXhP6H8leH/tvyd4b+g/KPhf4VFwCOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4HgPAMcFgDO+BzgR2UN/qfytof+k/LOhf7b8j6G/vPy1of+6/KWh/7n866F/uPxlof/JBYBjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAON4DwPkL8Xrl1oAElfoAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 211\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaElEQVR4nO3ZwQ2AIBAAQTT2Yf9lWQn2oCZqduYPx2PD55Y5jznI2t5+AGOMZb92bh63R6+3b+DXBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIM428Ase2Opd5QeIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxJ5+/CMLKmhB+AAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 211\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D4C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADDklEQVR4nO2dsW9OcRRA7xMTMYvl68BGmtLEJKnEpEEsdDAxVAc20RhExCAVG0N1YDJgEaQmiSYmSWkaNob3LWIW1p/lvn/gfibnnP30Lid3eff7tWutbyFYdkZERDe1XLJbv5L+dNHfTn9P0f+V/lLRX03/edE/n/7Bov81/ZIerY/014r+4o7aZPlfMAA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYAJzOz8Fs3ABwhnuAvSW79T/TXy36S+kvFv219OeK/kb6R4r+p/RPFf036a8U/eX014v+vBsAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOB4DwDHDQBnuAc4V7Jb/yL9XUX/T/rXiv799A8X/c8REV03mi/pbbye8w8U539L/3bRv5X+saL/wQ0AxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHC8B4DjBoAz3APsK9mt/5H+7qL/O/3Zor+Zful7frR++J7/oOhfjYjoutH1kt7G93L+s+L8hfTfF/3jbgA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgOM9ABw3AJzhHuB0yW796/RvFv07ERFdN7pR0tv4bs7fKM6fS3+66G+nv1D0n6U/6f8bOFP0X7kB4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACO9wBw3ABwhnuAhyW79VfSv1j0n6R/ueg/iojoulFNb+PI+cU/0I/TL7/X/4/mHy36H90AcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHewA4bgA4wz3ATMlu/Vb6U0W/T/9k0X+bful9gWj98L7AoaL/Jf1J7wEmfR/gQtF/6gaAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADjeA8BxA8AZ7gEm+n1+dFMniv679JeK/mr6L4v+2fRni/5m+vuL/vf0Hxf9S+nPFP0tNwAcA4BjAHAMAI4BwDEAOAYAxwDgGAAcA4BjAHAMAI4BwPEeAM5fVwrl1lxENfMAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Target Q matrix: step 221\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D4C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAABaUlEQVR4nO3ZwQnDQAwAQV1wH+m/LFdy7sEELrAzf4Eeiz5ae997yPqcXoCzBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQNx1eoGZmVnfd3P7/u0eQS5AnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcT9xzfQV+8YFyBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxD301QjCs20YYgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q_matrix of initial state, after training: step 221\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=128x128 at 0x19DFDF5D2B0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADAklEQVR4nO2dPY9NYRRG3yMKhZ5CRoGgUPoWJhkKQlCIdgpDJPQyiRiRTPQkwiimFQVCKJhkiG+lAkFxJwp6he5o9v0Dz1VZa/Uru1nZzdknb9f3g74JluWttda6tbOR3Q+my98U+p/LXxn6v8u/EvoXy18M/fHyt4b+h/IjvfWDVv586E8uyybL/4IBwDEAOAYAxwDgGAAcA4BjAHAMAI4BwDEAOAYAxwDgdH4OZuMGgDO8B1gT2f3gR/n3Q/9Y+edD/1r5o36P3xv6L8o/EvoPyx/1nuFe6B93A8AxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHO8B4LgB4AzvAU5Gdj+4U/6q0P9V/o3QP1v+ztB/01prXTc2Hun90mLN3xjO/1L+TOjPlB/fQ7gB4BgAHAOAYwBwDACOAcAxADgGAMcA4BgAHAOAYwBwDACO9wBw3ABwhvcAGyK7H3wtf0Xo/yl/T+i/LP9A6D8t/3ron2utta4buxrp/dKFmj8Xzp8qfyH0J9wAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHewA4bgA4w3uAw5HdDx6Vfzn0L7XWWteNzUd6vzRZ85+E8w+Wvy3035c/6nsB+0L/eflHQ/+BGwCOAcAxADgGAMcA4BgAHAOAYwBwDACOAcAxADgGAMcA4HgPAMcNAGd4DzDq+/VToT9X/unQv9Vaa103lun9Uqv568P538rfHfqvyl8d+j/LPxT6j90AcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjgHAMQA4BgDHewA4bgA4/+q9gC2h/7H8Uf+vnw396fK3h/678neE/tvyJ0J/ofwToX/XDQDHAOAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcLwHgOMGgDO8B5iJ7H4wU/7+0H9W/qnQv13+zdA/U/6u0H9d/rrQ/17+XOhPlb859D+5AeAYABwDgGMAcAwAjgHAMQA4BgDHAOAYABwDgGMAcAwAjvcAcP4CgCrl1tme+a4AAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# New model\n",
    "board = Board()\n",
    "model = Model()\n",
    "learning_rate = 0.3\n",
    "batch_size = 32\n",
    "n_epochs = 256 # On aura pas joué tous les coups mais OK\n",
    "max_history = 64\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# (Action, Reward) container for each action\n",
    "history = []\n",
    "\n",
    "# Populating the history with every possible move\n",
    "for i_epoch in range(n_epochs):\n",
    "    # Reset the board\n",
    "    initial_s, _ = board.reset()\n",
    "    initial_s = torch.tensor(initial_s, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    # Play a random action\n",
    "    a = torch.randint(0, 65, (1,)).item()\n",
    "    encoded_a = encode_action(a)\n",
    "\n",
    "    # Perform the action in the game\n",
    "    s, signal = board.step(encoded_a)\n",
    "\n",
    "    # Process the signal\n",
    "    r = reward_from_signal(signal, board)\n",
    "\n",
    "    # Add the record to history\n",
    "    history.append((a, r))\n",
    "\n",
    "    # Continue playing if we don't have enough moves to learn in the history\n",
    "    if len(history) <= batch_size:\n",
    "        continue\n",
    "\n",
    "    # Keep history the wanted size removing first element in list\n",
    "        if len(history) > max_history:\n",
    "            history.pop(0)\n",
    "\n",
    "    # Add the reward and action for each game in history\n",
    "    # NOTE: ça overwrite si y'a plusieurs valeurs, donc batch_size devrait être < 65\n",
    "    # TODO: moyenne des valeurs ? pas d'overwrite ?\n",
    "    targets = torch.zeros(batch_size, 65)\n",
    "    inputs = torch.zeros(batch_size, 2, 8, 8)\n",
    "    for i_batch, (a, r) in enumerate(random.sample(history, batch_size)):\n",
    "        # Q Learning matrix for the initial state\n",
    "        # NOTE: Je pense qu'il faudrait partir de la prédiction du modèle\n",
    "        # et y ajouter les rewards, les cases où il y a 0 peuvent peut-être\n",
    "        # poser problème\n",
    "        target_q = torch.zeros((65,), dtype=torch.float)#model(initial_s).view(-1)# torch.zeros((65,), dtype=torch.float)\n",
    "        target_q[a] = r\n",
    "        targets[i_batch] = target_q\n",
    "        inputs[i_batch] = initial_s\n",
    "\n",
    "    # Toggle on train mode\n",
    "    model.train()\n",
    "\n",
    "    # for i_batch in range(4):\n",
    "    # Compute loss on the difference between model output and target_q\n",
    "    inputs = torch.tensor(inputs)\n",
    "    targets = torch.tensor(targets)\n",
    "    q_pred = model(inputs)        \n",
    "    q_pred = torch.clip(q_pred, -3, 3)\n",
    "    loss = criterion(targets, q_pred)\n",
    "\n",
    "    # Let the optimizer do the backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i_epoch - batch_size) % 10 == 0:\n",
    "        print(f\"Target Q matrix: step {i_epoch - batch_size + 1}\")\n",
    "        render_q(target_q.tolist())\n",
    "\n",
    "        print(f\"Q_matrix of initial state, after training: step {i_epoch - batch_size + 1}\")\n",
    "        q_pred = model(torch.tensor(initial_s, dtype=torch.float))\n",
    "        render_q(q_pred.tolist()[0])"
   ]
  },
  {
   "source": [
    "## Etape 4 : mouvements futurs et epsilon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Board' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a400a28cd0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# New model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Board' is not defined"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "board = Board()\n",
    "test_board = Board()\n",
    "model = Model()\n",
    "model.to(device)\n",
    "epsilon = [0.9]\n",
    "epsilon_start = 1\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 512\n",
    "learning_rate = 0.001\n",
    "gamma = 0.9\n",
    "batch_size = 32\n",
    "max_history = 1024\n",
    "n_epochs = 4096*2\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# (State, Action, NextState, Reward, Done) container for each action\n",
    "history = []\n",
    "mean_length = []\n",
    "\n",
    "# Populating the history with every possible move\n",
    "for i_epoch in range(n_epochs):\n",
    "    # Reset the board\n",
    "    done = False\n",
    "    s, signal = board.reset()\n",
    "    s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    # Play a full game\n",
    "    length = 0\n",
    "    total_r = 0\n",
    "    while not done:\n",
    "\n",
    "        #========================== ACTION\n",
    "        # Play a random action or ask the model\n",
    "        a = 0\n",
    "        if length > len(epsilon):\n",
    "            epsilon.append(epsilon_start)\n",
    "        else:\n",
    "            epsilon[length] = epsilon_end + (epsilon_start - epsilon_end) * math.exp(-1. * i_epoch / epsilon_decay)\n",
    "        if np.random.rand() <= epsilon[length]:\n",
    "            a = torch.randint(0, 65, (1,)).item()\n",
    "        else:\n",
    "            a_scores = model(s.to(device))\n",
    "            a = torch.argmax(a_scores).item()\n",
    "        encoded_a = encode_action(a)\n",
    "\n",
    "        # Perform the action in the game\n",
    "        n_s, signal = board.step(encoded_a)\n",
    "        n_s = torch.tensor(n_s, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "        # Process the signal\n",
    "        r = reward_from_signal(signal, board) + length / 2\n",
    "        total_r += r\n",
    "        done = game_over_from_signal(signal, board)\n",
    "        #-------------------------- ACTION\n",
    "\n",
    "        #========================== BLACK SAMPLE MOVE\n",
    "        black_action = board.sample()\n",
    "        n_s, signal = board.step(black_action)\n",
    "        n_s = torch.tensor(n_s, dtype=torch.float).unsqueeze(0)\n",
    "        #-------------------------- BLACK SAMPLE MOVE\n",
    "\n",
    "        #========================== HISTORY\n",
    "        # Add the record to history\n",
    "        for i_history in range(length):\n",
    "            history.append((s, a, r, n_s, done))\n",
    "        \n",
    "        # Update current state\n",
    "        s = n_s\n",
    "\n",
    "        # Continue playing if we don't have enough moves to learn in the history\n",
    "        if len(history) <= batch_size:\n",
    "            continue\n",
    "\n",
    "        # Keep history the wanted size removing first element in list\n",
    "        while len(history) > max_history:\n",
    "            history.pop(0)\n",
    "        #-------------------------- HISTORY\n",
    "\n",
    "        #========================== Q LEARNING\n",
    "        # Q Learning matrix for the initial state\n",
    "        targets = torch.zeros(batch_size, 65)\n",
    "        inputs = torch.zeros(batch_size, 2, 8, 8)\n",
    "        i_batch = 0\n",
    "        samples = random.sample(history, batch_size - 1) + [history[-1]]\n",
    "        for i_batch, (s_, a_, r_, n_s_, done_) in enumerate(samples):\n",
    "            # Build bellman equation for the Q function\n",
    "            inputs[i_batch] = s_\n",
    "            targets[i_batch] = model(s_.to(device)).view(-1) # torch.zeros((65,), dtype=torch.float)\n",
    "            Q_sa = model(n_s_.to(device))\n",
    "\n",
    "            # Emplace reward\n",
    "            if done_:\n",
    "                targets[i_batch, a_] = r_\n",
    "            else:\n",
    "                targets[i_batch, a_] = r_ + gamma * torch.max(Q_sa)\n",
    "\n",
    "\n",
    "        # Compute loss on the difference between model output and target_q\n",
    "        model.train()\n",
    "        q_pred = model(inputs.to(device))        \n",
    "        targets = torch.clip(targets, -3, 3)\n",
    "        loss = criterion(targets.to(device), q_pred)\n",
    "\n",
    "        # Let the optimizer do the backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update length\n",
    "        length += 1\n",
    "    \n",
    "    if len(mean_length) <= 50:\n",
    "        mean_length.append(length)\n",
    "    else:\n",
    "        mean_length.pop(0)\n",
    "    print(f\"Epoch {i_epoch} \\t reward: {total_r} \\t length {length} \\t mean_length {int(np.mean(mean_length) * 100)/100} \\t epsilon {np.floor(epsilon*100)/100}\")\n",
    "    \n",
    "    # Display matrixes\n",
    "    if i_epoch > batch_size and (i_epoch - batch_size) % 100 == 1:\n",
    "        print(f\"Q_matrix of initial state, after training: step {i_epoch - batch_size}\")\n",
    "        s, signal = test_board.reset()\n",
    "        s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "        a_scores = model(s.to(device))\n",
    "        q1 = a_scores.to(\"cpu\")\n",
    "        render_q(q1.tolist()[0])\n",
    "        a = torch.argmax(a_scores).item()\n",
    "        encoded_a = encode_action(a)\n",
    "        n_s, signal = test_board.step(encoded_a)\n",
    "        if not game_over_from_signal(signal, test_board):\n",
    "            black_action = test_board.sample()\n",
    "            n_s, signal = test_board.step(black_action)\n",
    "            n_s = torch.tensor(n_s, dtype=torch.float).unsqueeze(0)\n",
    "            a_scores = model(n_s.to(device))\n",
    "            q2 = a_scores.to(\"cpu\")\n",
    "            render_q(q2.tolist()[0])\n",
    "            render_q((q2 - q1).tolist()[0])\n",
    "            a = torch.argmax(a_scores).item()\n",
    "            encoded_a = encode_action(a)\n",
    "        play_one_game(model, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (input_layer): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (hidden_layer_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (hidden_layer_21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (hidden_layer_3): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "  (hidden_layer_4): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"model.save\"))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(model, render=False):\n",
    "    board = Board()\n",
    "    s, sig = board.reset()\n",
    "    board.render()\n",
    "    s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "    count = 0\n",
    "    while True:\n",
    "        # White moves\n",
    "        count += 1\n",
    "        Q = model(s.to(device))\n",
    "        iQmax = torch.argmax(Q).item()\n",
    "        a = encode_action(iQmax)\n",
    "        print(f\"White {count}:\\t{a}\")\n",
    "        s, sig = board.step(a)\n",
    "        print(f\"Res:\\t{sig}\")\n",
    "        if render:\n",
    "            board.render()\n",
    "        s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "        if game_over_from_signal(sig, board):\n",
    "            break\n",
    "        # Black moves\n",
    "        a = board.sample()\n",
    "        print(f\"Black {count}:\\t{a}\")\n",
    "        s, sig = board.step(a)\n",
    "        print(f\"Res:\\t{sig}\")\n",
    "        if render:\n",
    "            board.render()\n",
    "        s = torch.tensor(s, dtype=torch.float).unsqueeze(0)\n",
    "        if game_over_from_signal(sig, board):\n",
    "            break"
   ]
  }
 ]
}